import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# --------- Data Generation ---------
def true_function(x):
    """The true function we aim to approximate (sinusoidal)."""
    return np.sin(1.5 * np.pi * x)

np.random.seed(0)
n_samples = 30
# Generate random X values between 0 and 1
X = np.sort(np.random.rand(n_samples))
# Add Gaussian noise to the true function
y = true_function(X) + np.random.normal(0, 0.15, size=X.shape)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)

degrees = [1, 4, 15]  # Model complexities to demonstrate underfitting, good fit, and overfitting
plt.figure(figsize=(18, 5))

for i, degree in enumerate(degrees):
    # --------- Feature Transformation ---------
    # Transform input data to polynomial features of given degree
    poly = PolynomialFeatures(degree)
    X_train_poly = poly.fit_transform(X_train[:, np.newaxis])
    X_test_poly = poly.transform(X_test[:, np.newaxis])
    X_plot = np.linspace(0, 1, 100)
    X_plot_poly = poly.transform(X_plot[:, np.newaxis])

    # --------- Model Training ---------
    model = LinearRegression()
    model.fit(X_train_poly, y_train)
    y_pred = model.predict(X_plot_poly)

    # --------- Plotting ---------
    plt.subplot(1, 3, i + 1)
    plt.scatter(X_train, y_train, color='red', label='Train data')
    plt.scatter(X_test, y_test, color='green', label='Test data')
    plt.plot(X_plot, true_function(X_plot), label='True Function', linestyle='dashed')
    plt.plot(X_plot, y_pred, label=f'Prediction (degree={degree})')
    plt.ylim(-1.5, 1.5)
    plt.xlabel('x')
    plt.ylabel('y')
    plt.legend()
    plt.title(f'Degree {degree}\n'
              + ('Underfitting' if degree == 1 else 'Overfitting' if degree == 15 else 'Good Fit'))

plt.suptitle('Underfitting (left), Good Fit (middle), Overfitting (right)\n'
             'Red = Train, Green = Test, Dashed = True Function, Blue = Model')
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

# --------- Learning Curve Plot (Bias-Variance Tradeoff) ---------
train_errors = []
test_errors = []
degrees = range(1, 16)
for degree in degrees:
    poly = PolynomialFeatures(degree)
    X_train_poly = poly.fit_transform(X_train[:, np.newaxis])
    X_test_poly = poly.transform(X_test[:, np.newaxis])
    model = LinearRegression()
    model.fit(X_train_poly, y_train)
    # Calculate mean squared error on train and test sets
    train_errors.append(mean_squared_error(y_train, model.predict(X_train_poly)))
    test_errors.append(mean_squared_error(y_test, model.predict(X_test_poly)))

plt.figure(figsize=(8, 5))
plt.plot(degrees, train_errors, marker='o', label='Train Error')
plt.plot(degrees, test_errors, marker='s', label='Test Error')
plt.xlabel('Model Complexity (Polynomial Degree)')
plt.ylabel('Mean Squared Error')
plt.title('Bias-Variance Tradeoff\nTrain vs Test Error')
plt.legend()
plt.grid(True)
plt.show()

# --------- Explanatory Comments ---------
# - Degree 1 (Underfitting): The model is too simple (high bias), cannot capture the curve of the true function.
# - Degree 4 (Good Fit): The model captures the true pattern well, low bias and moderate variance.
# - Degree 15 (Overfitting): The model is too complex (high variance), fits noise in the training data and performs poorly on the test set.
# - The learning curve shows: train error always decreases with complexity; test error decreases, then increases (U-shaped), visualizing the bias-variance tradeoff.
