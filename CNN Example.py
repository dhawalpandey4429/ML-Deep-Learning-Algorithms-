# -*- coding: utf-8 -*-
"""Assig_CNN_DL_Class.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1moFeL_9Ko7ZCmk1Q561_fRvdgNlaGPlc
"""

pip install tensorflow

import tensorflow as tf
from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout
from tensorflow.keras import Sequential
from tensorflow.keras.datasets import mnist

import numpy as np

(x_train, y_train), (x_test, y_test) = mnist.load_data()

model = Sequential()

model.add(Conv2D(32, kernel_size=(3,3),padding="valid",activation="relu",input_shape=(28,28,1)))
model.add(Conv2D(32, kernel_size=(3,3),padding="valid",activation="relu"))
model.add(Conv2D(32, kernel_size=(3,3),padding="valid",activation="relu"))
model.add(Flatten())

model.add(Dense(128,activation="relu"))
model.add(Dense(10,activation="softmax"))

model.summary()

model = Sequential()

model.add(Conv2D(32, kernel_size=(3,3),padding="same",activation="relu",input_shape=(28,28,1)))
model.add(Conv2D(32, kernel_size=(3,3),padding="same",activation="relu"))
model.add(Conv2D(32, kernel_size=(3,3),padding="same",activation="relu"))
model.add(Flatten())

model.add(Dense(128,activation="relu"))
model.add(Dense(10,activation="softmax"))

model.summary()

model = Sequential()

model.add(Conv2D(32, kernel_size=(3,3),padding="same", strides=(1,1) ,activation="relu",input_shape=(28,28,1)))
model.add(Conv2D(32, kernel_size=(3,3),padding="same",strides=(2,2), activation="relu"))
model.add(Conv2D(32, kernel_size=(3,3),padding="same",strides=(3,3), activation="relu"))
model.add(Flatten())

model.add(Dense(128,activation="relu"))
model.add(Dense(10,activation="softmax"))

model.summary()

"""-----
Multiclass classification with dropout
"""

import matplotlib.pyplot as plt
from tensorflow.keras import models

(x_train, y_train), (x_test, y_test) = mnist.load_data()

# preprocessing data
x_train = x_train.reshape(x_train.shape[0],28,28,1)
x_test = x_test.reshape(x_test.shape[0],28,28,1)
x_train, x_test = x_train/255.0, x_test/255.0

# convert labels to one hot encoding
y_train = tf.keras.utils.to_categorical(y_train,10)
y_test = tf.keras.utils.to_categorical(y_test,10)

# CNN model with dropout
def model_with_dropout():
  model = Sequential([
      Conv2D(32,(3,3),activation="relu",input_shape=(28,28,1)),
      MaxPooling2D((2,2)),
      Conv2D(64,(3,3),activation="relu"),
      MaxPooling2D((2,2)),
      Conv2D(64,(3,3),activation="relu"),
      Flatten(),
      Dense(64,activation="relu"),
      Dropout(0.5),
      Dense(10,activation="softmax")
  ])
  model.compile(optimizer="adam",loss="categorical_crossentropy",metrics=["accuracy"])
  return model

z = model_with_dropout()

z.summary()

history_with_dropout = z.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))

def model_without_dropout():
  model = Sequential([
      Conv2D(32,(3,3),activation="relu",input_shape=(28,28,1)),
      MaxPooling2D((2,2)),
      Conv2D(64,(3,3),activation="relu"),
      MaxPooling2D((2,2)),
      Conv2D(64,(3,3),activation="relu"),
      Flatten(),
      Dense(64,activation="relu"),
      Dense(10,activation="softmax")
  ])
  model.compile(optimizer="adam",loss="categorical_crossentropy",metrics=["accuracy"])
  return model

y = model_with_dropout()
history_without_dropout = y.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))

"""---
## Loading Dataset from Kaggle using API
"""

! pip install -q kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

!kaggle datasets download -d gpiosenka/sports-classification

! unzip "sports-classification.zip"

import pandas as pd

df = pd.read_csv("sports.csv")
df.head()

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image

for path in df["filepaths"]:
  plt.imshow(mpimg.imread(path))
  img = Image.open(path)
  width, height = img.size
  print(width,height)
  plt.show()

  break

"""---
## Making a model with transfer learning
"""

import tensorflow as tf
from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras import Sequential
from tensorflow.keras.applications import ResNet50

base_model = ResNet50(weights="imagenet",include_top=False,input_shape=(224,224,3))

base_model.trainable = False

base_model.summary()

import tensorflow as tf

# Load train dataset
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    "train",
    image_size=(224, 224),
    batch_size=32,
    label_mode='categorical'jj

# Load validation dataset
valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    "valid",
    image_size=(224, 224),
    batch_size=32,
    label_mode='categorical'
)

# Check class names
class_names = train_dataset.class_names
print("Classes:", class_names)

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(512, activation='relu'),
    Dropout(0.3),
    Dense(100, activation='softmax')
])
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
history = model.fit(train_dataset, epochs=20, validation_data=valid_dataset)

plt.figure(figsize=(12, 6))

# Plot training accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plot training and validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Show plots
plt.tight_layout()
plt.show()

# Evaluate model performance on the validation dataset
val_loss, val_accuracy = model.evaluate(valid_dataset)

# Print results
print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

# Get one batch of images and labels from the validation dataset
for images, labels in valid_dataset.take(1):
    sample_image = images[0]  # Take the first image from the batch
    break

# Expand dimensions to match the input shape expected by the model (batch size of 1)
image_for_prediction = tf.expand_dims(sample_image, axis=0)

# Make a prediction
predictions = model.predict(image_for_prediction)

# Get the class with the highest probability
predicted_class = np.argmax(predictions, axis=1)[0]

# Get class labels from dataset
class_names = valid_dataset.class_names  # If using `image_dataset_from_directory`
predicted_label = class_names[predicted_class]

# Plot the image
plt.imshow(sample_image.numpy().astype("uint8"))
plt.axis("off")
plt.title(f"Predicted: {predicted_label}")
plt.show()

